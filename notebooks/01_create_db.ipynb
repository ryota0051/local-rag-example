{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d2616b-41c1-4399-a3d2-a12bdbdc2fe1",
   "metadata": {},
   "source": [
    "## ベクトルデータをDBに登録する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdb845e3-9766-43fa-98da-03205a0e01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import InfinityEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402d4caf-83d1-4213-a750-a1661b792292",
   "metadata": {},
   "source": [
    "## 定数定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d9ce875-d8a8-4b8b-b13d-a78186a73b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_PATH = 'sbintuitions/sarashina-embedding-v2-1b'\n",
    "\n",
    "PDF_PATH = '/app/data/input.pdf'\n",
    "DB_DIR = '/app/chroma_db'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a8d398-6204-451c-9aec-3fb57097c4da",
   "metadata": {},
   "source": [
    "## DB作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a83d3c0-22ad-4946-84e3-dad187c027bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "既存のデータベースを削除しました\n"
     ]
    }
   ],
   "source": [
    "# PDF読み込み\n",
    "loader = PyPDFLoader(PDF_PATH)\n",
    "documents = loader.load()\n",
    "\n",
    "# チャンク分割\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,      # 1つのチャンクの文字数\n",
    "    chunk_overlap=200     # チャンク間の重複文字数\n",
    ")\n",
    "splits = text_splitter.split_documents(documents)\n",
    "enhanced_splits = []\n",
    "for doc in splits:\n",
    "    # 元の文書内容にクエリテンプレートを追加\n",
    "    query_enhanced_content = f\"text: {doc.page_content}\"\n",
    "    \n",
    "    # 新しいDocumentオブジェクトを作成\n",
    "    from langchain_core.documents import Document\n",
    "    enhanced_doc = Document(\n",
    "        page_content=query_enhanced_content,\n",
    "        metadata=doc.metadata\n",
    "    )\n",
    "    enhanced_splits.append(enhanced_doc)\n",
    "splits = enhanced_splits\n",
    "\n",
    "# 埋め込み\n",
    "embeddings = InfinityEmbeddings(\n",
    "    model=EMBEDDING_MODEL_PATH,\n",
    "    infinity_api_url='http://proxy',\n",
    ")\n",
    "if os.path.exists(DB_DIR):\n",
    "    shutil.rmtree(DB_DIR)\n",
    "    print(\"既存のデータベースを削除しました\")\n",
    "\n",
    "# ベクトルDB作成\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=DB_DIR\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e72111f1-4500-4380-ac21-29849ac34667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "text: 7 \n",
      "用語 解説 \n",
      "生成 AI 出力が単一の数値やラベルではなく、文章や画像や音声や動画といっ\n",
      "た従来は人間が創作していた類のものを出力する機械学習モデルを使っ\n",
      "たシステムのことを総称したもの。 \n",
      "テキスト生成\n",
      "AI \n",
      "生成 AI のうち、出力が文章に代表されるテキストのもの。出力は文章\n",
      "以外でもソースコード等やテキストデータの形式を変換したものといっ\n",
      "た自然言語以外の出力や、文章分類や固有表現抽出等といった従来の自\n",
      "然言語処理課題を行うことも可能である。 \n",
      "大規模言語モ\n",
      "デル \n",
      "昨今のテキスト生成 AI の背後にいることの多いニューラルネットワー\n",
      "ク型の機械学習モデルの一種で、膨大なパラメータ数と膨大なテキスト\n",
      "により学習されていることが特徴の一つ。 \n",
      "テキスト生成 AI の背後は必ずしも大規模言語モデルではない（機械翻\n",
      "訳での LSTM 等）点や、大規模言語モデルの小型化研究が盛んであり必ず\n",
      "しも「大規模」とは限らない点が混乱しやすい。 \n",
      "プロンプト 大規模言語モデルへ入力するテキストデータのこと。 \n",
      "膨大なテキストによる教師なし学習を事前学習とよび、特定の課題（下\n",
      "流タスクとも呼ぶ）に特化させた事後学習(ファインチューニング)とよ\n",
      "ぶ。以前はこの事後学習によりさまざまな自然言語処理課題に対応させ\n",
      "る手法が主流だったが、大規模言語モデルではプロンプトによる指示を\n",
      "変えるだけでさまざまな自然言語処理課題に対応することが可能になっ\n",
      "た。 \n",
      "トークン 自然言語を機械学習モデル等のシステムに扱いやすい単位で分割した\n",
      "もの。日本語の場合、検索エンジンへは n-gram や形態素といった単位で\n",
      "トークンが作られることが多く、大規模言語モデルへはサブワードとい\n",
      "ったさらに細かい分割が一般に行われる。 \n",
      "表２ 本文書の用語集\n",
      "----------------------------------------------------------------------------------------------------\n",
      "text: 10 \n",
      "ここでは、情報検索サービスにテキスト生成AIを利活用する方法の一例を、\n",
      "旧来の利便性のあまり高くないチャットボット型の サービスと比較して述べる。 \n",
      "旧来の利便性のあまり高くないチャットボット型サービスの典型的な挙動は\n",
      "以下である。 \n",
      "➢ チャットボットが潜在的に返すことのできる回答候補の数が少なく、必\n",
      "要とする回答をサービス利用者がどんなに入力しても得られない \n",
      "➢ サービス利用者に文章で入力させるが、文中の単語の一部を抽出するだ\n",
      "けで文意は無視される。また単語で検索されるが単語の表記揺れなどは\n",
      "考慮されない。 \n",
      "➢ チャットボットから返された検索結果の内容の理解に困難を伴い、関連\n",
      "が低い回答内容を読解するためのサービス利用者への負荷が高い。 \n",
      "これらの課題は情報検索システムを中心とすると下記のように図示できる。 \n",
      " \n",
      " \n",
      "図１ 情報検索システムでユーザビリティ向上を生成 AI で実現できる箇所 \n",
      " \n",
      "これらすべての箇所でテキスト生成AIは旧来のチャットボット型サービスあ\n",
      "るいは検索システムを改善できる。詳細は８ 従来型の情報検索サービスをテ\n",
      "キスト生成 AI により改善する手法 で述べる。 \n",
      "テキスト生成AIによる国民向けへの質の高い情報検索サービスの構築には、\n",
      "いわゆる ChatGPT のようなユースケース 1 に限らず、ユースケース 3 の旧来の\n",
      "情報検索システムの考え方を前提にしたテキスト生成AIによる利便性の向上に\n",
      "も検討の価値がある。特にこの手法の優位点は事前に準備した回答候補をベー\n",
      "スとするため原理的には事前にすべての回答パターンをテストできるため高い\n",
      "品質要件を満たすことができる点である。また、テキスト生成AIを主にバッチ\n",
      "処理で用いることでコスト予測が立てやすいため予算要求前での見積もり精度\n",
      "を上げることもできる。こちらは５．２ ４） テスト済みの生成物のみを用\n",
      "いる場合の工夫 でも詳細に述べる。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "text: 17 \n",
      "で開発できていないため、ここでは留意点の紹介に留まる。 \n",
      " \n",
      "提供形態 開発コスト カスタマイズ性 運用コスト \n",
      "テキスト生\n",
      "成AI を組み\n",
      "込んだサービ\n",
      "スとして提供\n",
      "されるケース \n",
      "既にあるものを利用\n",
      "するため基本的には無\n",
      "い \n",
      "既存の情報システム\n",
      "にテキスト生成AI を組\n",
      "み込む場合は選択肢に\n",
      "挙がらない \n",
      "基本的には低い。サービ\n",
      "ス提供元会社と直接委託契\n",
      "約を結び、こちらの要望を\n",
      "積極的に取り入れる場合\n",
      "は、カスタマイズ性も高くな\n",
      "る  \n",
      "サービス利用料程度し\n",
      "かかからず、既に利用マニ\n",
      "ュアルやヘルプデスクが準\n",
      "備されている場合もあり \n",
      "テキスト生\n",
      "成AI を利用\n",
      "するための\n",
      "Web API が\n",
      "クラウドサー\n",
      "ビスとして提\n",
      "供されるケー\n",
      "ス \n",
      "Web API を経由でテ\n",
      "キスト生成AI を利用す\n",
      "るだけであれば開発コ\n",
      "ストは少ない \n",
      "既存の情報システム\n",
      "にテキスト生成AI を組\n",
      "み込む場合はプロンプ\n",
      "トの試行錯誤やテスト\n",
      "工数が通常のシステム\n",
      "開発と比べて大きい \n",
      "さまざまな種類の大規模\n",
      "言語モデルが主要なクラウ\n",
      "ドサービスによってWeb \n",
      "API 形式で提供されてい\n",
      "る。独自に学習した大規模\n",
      "言語モデルを使うオプション\n",
      "もあり、テキスト生成AI 部\n",
      "分のカスタマイズ性は最も\n",
      "高い \n",
      "入出力のトークン数や文\n",
      "字数に比例する料金形態\n",
      "をとっていることが多く、コ\n",
      "スト試算が独特になる。利\n",
      "用する大規模言語モデル\n",
      "によって価格が大きく異な\n",
      "るため、品質要求と運用コ\n",
      "ストのバランスが求められ\n",
      "る \n",
      "テキスト生\n",
      "成AI の機械\n",
      "学習モデルが\n",
      "直接提供され\n",
      "るケース \n",
      "オンプレミスでのサー\n",
      "バ調達やクラウド上で\n",
      "の計算環境を用意し、\n",
      "その上にテキスト生成\n",
      "AI を利用するための開\n",
      "発が必要になるため、\n",
      "開発コストは最も高い \n",
      "利用できる大規模モデル\n",
      "に制約がかかり、最高峰の\n",
      "大規模言語モデルが利用\n",
      "できない可能性が高い \n",
      "インターネットを利用しな\n",
      "くても良いので、ネットワー\n",
      "ク要件やセキュリティ要件に\n",
      "応じたカスタマイズ性は最も\n",
      "高い \n",
      "ハードウェアのメンテナ\n",
      "ンスやメモリ管理などでや\n",
      "らなければならないことが\n",
      "多いため、3 つの中では最\n",
      "も運用コストが高い傾向が\n",
      "ある \n",
      "ただし潤沢な計算リソー\n",
      "スが確保でき、テキスト生\n",
      "成 AI の利用頻度が非常に\n"
     ]
    }
   ],
   "source": [
    "test_results = vectorstore.similarity_search(\"task: クエリに関連した文章を検索してください \\\\n query: 生成AIとは?\", k=3)\n",
    "for result in test_results:\n",
    "    print(\"-\" * 100)\n",
    "    print(result.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f03b8-38ac-4af7-bd5b-96263b4547c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
